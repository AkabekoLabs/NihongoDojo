"""
æ—¥æœ¬èªã‚¿ã‚¹ã‚¯ç”¨ã®å ±é…¬é–¢æ•°
"""

import re
from collections import defaultdict


class JapaneseTaskRewardFunctions:
    """æ—¥æœ¬èªã‚¿ã‚¹ã‚¯ç”¨ã®å ±é…¬é–¢æ•°ã‚’æä¾›ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, reasoning_start="<reasoning>", reasoning_end="</reasoning>",
                 solution_start="<answer>", solution_end="</answer>", 
                 eos_token="", accuracy_stats=None):
        self.reasoning_start = reasoning_start
        self.reasoning_end = reasoning_end
        self.solution_start = solution_start
        self.solution_end = solution_end
        self.eos_token = eos_token
        
        # çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜
        self.accuracy_stats = accuracy_stats or defaultdict(list)
        
        # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆ
        self._create_regex_pattern()
    
    def _create_regex_pattern(self):
        """ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç¢ºèªç”¨ã®æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆ"""
        solution_end_regex = r"</answer>[\s]{0,}"
        if self.eos_token:
            solution_end_regex += "(?:" + re.escape(self.eos_token) + ")?"
        
        self.match_format = re.compile(
            rf"{self.reasoning_end}.*?"
            rf"{self.solution_start}(.+?){solution_end_regex}"
            rf"[\s]{{0,}}$",
            flags=re.MULTILINE | re.DOTALL
        )
    
    def match_format_exactly(self, prompts=None, completions=None, completion_ids=None, **kwargs):
        """ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å®Œå…¨ä¸€è‡´ã‚’ç¢ºèªï¼ˆçµ±è¨ˆåé›†ä»˜ãï¼‰"""
        # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¯¾å¿œ
        if prompts is not None and completions is not None:
            responses = completions
        else:
            # å¤ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
            responses = kwargs.get('completions', [])
        
        scores = []
        format_success = 0
        
        for response in responses:
            score = 0
            # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®å ´åˆã¯æ–‡å­—åˆ—ã€å¤ã„å ´åˆã¯è¾æ›¸
            if isinstance(response, str):
                text = response
            elif isinstance(response, list) and len(response) > 0:
                text = response[0].get("content", "") if isinstance(response[0], dict) else str(response[0])
            else:
                text = ""
            
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæ­£ç¢ºã«è¦‹ã¤ã‹ã£ãŸå ´åˆ
            if self.match_format.search(text) is not None:
                score += 1.0
                format_success += 1
                self.accuracy_stats['correct_format'].append(1)
            else:
                score = -1.0  # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
                self.accuracy_stats['correct_format'].append(0)
            
            scores.append(score)
        
        if len(scores) > 0:
            format_rate = format_success / len(scores) * 100
            print(f"ğŸ“‹ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ­£ç­”ç‡: {format_rate:.1f}%")
        
        return scores
    
    def match_format_approximately(self, prompts=None, completions=None, completion_ids=None, **kwargs):
        """ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®éƒ¨åˆ†ä¸€è‡´ã‚’ç¢ºèª"""
        # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¯¾å¿œ
        if prompts is not None and completions is not None:
            responses = completions
        else:
            # å¤ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
            responses = kwargs.get('completions', [])
        
        scores = []
        
        for response in responses:
            score = 0
            # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®å ´åˆã¯æ–‡å­—åˆ—ã€å¤ã„å ´åˆã¯è¾æ›¸
            if isinstance(response, str):
                text = response
            elif isinstance(response, list) and len(response) > 0:
                text = response[0].get("content", "") if isinstance(response[0], dict) else str(response[0])
            else:
                text = ""
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            score += 0.25 if text.count(self.reasoning_end) == 1 else -0.5
            score += 0.25 if text.count(self.solution_start) == 1 else -0.5
            score += 0.25 if text.count(self.solution_end) == 1 else -0.5
            
            scores.append(score)
        
        return scores
    
    def check_answer(self, prompts=None, completions=None, completion_ids=None, answer=None, **kwargs):
        """ç­”ãˆã®ç¢ºèªï¼ˆã‚ˆã‚Šå³æ ¼ãªè©•ä¾¡ã€çµ±è¨ˆåé›†ä»˜ãï¼‰"""
        # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¯¾å¿œ
        if prompts is not None and completions is not None:
            # answerãŒãƒ•ãƒ«ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³å½¢å¼ã®å ´åˆã€å®Ÿéš›ã®ç­”ãˆã‚’æŠ½å‡º
            if answer and len(answer) > 0 and isinstance(answer[0], str) and '<answer>' in answer[0]:
                # ãƒ•ãƒ«ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰å®Ÿéš›ã®ç­”ãˆã‚’æŠ½å‡º
                extracted_answers = []
                for ans in answer:
                    match = re.search(r'<answer>(.+?)</answer>', ans, re.DOTALL)
                    if match:
                        extracted_answers.append(match.group(1).strip())
                    else:
                        extracted_answers.append(ans)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                answer = extracted_answers
            
            # promptsã‹ã‚‰questionã¨ç­”ãˆã‚’æŠ½å‡º
            if prompts and len(prompts) > 0 and not answer:
                # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰è³ªå•ã‚’å–å¾—
                question = prompts[0] if isinstance(prompts[0], str) else prompts[0][-1].get("content", "")
                # ç­”ãˆã‚’æŠ½å‡º - "æ­£è§£:" ã®å¾Œã®éƒ¨åˆ†ã‚’æ¢ã™
                import re
                answer_match = re.search(r'æ­£è§£[ï¼š:]\s*([^\n]+)', question)
                if answer_match:
                    answer = [answer_match.group(1).strip()]
                elif not answer:
                    # ç­”ãˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç©ºãƒªã‚¹ãƒˆ
                    answer = [""] * len(completions)
            
            # completionsã‹ã‚‰å¿œç­”ã‚’æŠ½å‡º
            responses = []
            for completion in completions:
                if isinstance(completion, str):
                    responses.append(completion)
                elif isinstance(completion, list) and len(completion) > 0:
                    responses.append(completion[0].get("content", "") if isinstance(completion[0], dict) else str(completion[0]))
                else:
                    responses.append("")
        else:
            # å¤ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
            question = kwargs.get('question', '')
            answer = kwargs.get('answer', [])
            responses = kwargs.get('responses', [])
            if not responses and 'completions' in kwargs:
                completions = kwargs['completions']
                responses = [completion[0]["content"] for completion in completions]
        
        # ç­”ãˆãŒãƒªã‚¹ãƒˆã§ãªã„å ´åˆã¯ãƒªã‚¹ãƒˆã«å¤‰æ›
        if not isinstance(answer, list):
            answer = [answer] * len(responses)
        elif len(answer) == 1 and len(responses) > 1:
            # ç­”ãˆãŒ1ã¤ã—ã‹ãªã„å ´åˆã¯ã€å…¨ã¦ã®å¿œç­”ã«å¯¾ã—ã¦åŒã˜ç­”ãˆã‚’ä½¿ç”¨
            answer = answer * len(responses)
        
        extracted_responses = [
            guess.group(1)
            if (guess := self.match_format.search(r)) is not None else None
            for r in responses
        ]
        
        scores = []
        batch_stats = {'correct': 0, 'partial': 0, 'wrong': 0, 'no_answer': 0}
        
        for guess, true_answer in zip(extracted_responses, answer):
            score = 0
            if guess is None:
                scores.append(-2.0)
                batch_stats['no_answer'] += 1
                self.accuracy_stats['no_answer'].append(1)
                continue
            
            # ç­”ãˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            guess = guess.strip()
            true_answer = str(true_answer).strip()
            
            # å®Œå…¨ä¸€è‡´
            if guess == true_answer:
                score += 3.0
                batch_stats['correct'] += 1
                self.accuracy_stats['correct_answer'].append(1)
            # ã‚¹ãƒšãƒ¼ã‚¹ãªã—ã§ä¸€è‡´
            elif guess.replace(" ", "") == true_answer.replace(" ", ""):
                score += 2.5
                batch_stats['correct'] += 1
                self.accuracy_stats['correct_answer'].append(1)
            # ã²ã‚‰ãŒãª/ã‚«ã‚¿ã‚«ãƒŠã®é•ã„ã¯è¨±å®¹ï¼ˆãŸã ã—æ¸›ç‚¹ï¼‰
            elif guess.replace("ã€€", "").replace("ã€", "") == true_answer.replace("ã€€", "").replace("ã€", ""):
                score += 2.0
                batch_stats['partial'] += 1
                self.accuracy_stats['partial_answer'].append(1)
            else:
                # éƒ¨åˆ†ä¸€è‡´ã®è©•ä¾¡ã‚’ã‚ˆã‚Šè©³ç´°ã«
                if len(true_answer) == 1 and len(guess) == 1:
                    # å˜ä¸€æ–‡å­—ã®å ´åˆï¼ˆæ¼¢å­—ä¸€æ–‡å­—ãªã©ï¼‰
                    score = -1.5
                elif true_answer in guess or guess in true_answer:
                    # éƒ¨åˆ†ä¸€è‡´
                    match_ratio = min(len(guess), len(true_answer)) / max(len(guess), len(true_answer))
                    score += 1.0 * match_ratio
                    batch_stats['partial'] += 1
                    self.accuracy_stats['partial_answer'].append(1)
                else:
                    score = -1.5
                    batch_stats['wrong'] += 1
                    self.accuracy_stats['wrong_answer'].append(1)
            
            scores.append(score)
        
        # ãƒãƒƒãƒçµ±è¨ˆã‚’è¡¨ç¤º
        if len(scores) > 0:
            accuracy = batch_stats['correct'] / len(scores) * 100
            print(f"ğŸ“Š ãƒãƒƒãƒçµ±è¨ˆ - æ­£è§£ç‡: {accuracy:.1f}% | æ­£è§£: {batch_stats['correct']} | " +
                  f"éƒ¨åˆ†æ­£è§£: {batch_stats['partial']} | ä¸æ­£è§£: {batch_stats['wrong']} | ç„¡å›ç­”: {batch_stats['no_answer']}")
        
        # æŠ½å‡ºã•ã‚ŒãŸå›ç­”ã‚’kwargsã«è¿½åŠ ï¼ˆãƒ­ã‚°è¨˜éŒ²ç”¨ï¼‰
        kwargs['extracted_responses'] = extracted_responses
        
        return scores
    
    def check_reasoning_quality(self, prompts=None, completions=None, completion_ids=None, **kwargs):
        """æ€è€ƒéç¨‹ã®è³ªã‚’è©•ä¾¡"""
        # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¯¾å¿œ
        if prompts is not None and completions is not None:
            responses = completions
        else:
            # å¤ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
            responses = kwargs.get('completions', [])
        
        scores = []
        
        for response in responses:
            # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®å ´åˆã¯æ–‡å­—åˆ—ã€å¤ã„å ´åˆã¯è¾æ›¸
            if isinstance(response, str):
                text = response
            elif isinstance(response, list) and len(response) > 0:
                text = response[0].get("content", "") if isinstance(response[0], dict) else str(response[0])
            else:
                text = ""
            
            score = 0
            
            # reasoningéƒ¨åˆ†ã‚’æŠ½å‡º
            reasoning_match = re.search(
                rf"{self.reasoning_start}(.*?){self.reasoning_end}", 
                text, re.DOTALL
            )
            
            if reasoning_match:
                reasoning = reasoning_match.group(1)
                
                # æ¼¢å­—å­¦ç¿’ã«é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
                keywords = ["å¹´ç”Ÿ", "ç¿’ã†", "æ„å‘³", "èª­ã¿", "æ›¸ã", "æ¼¢å­—", "éŸ³èª­ã¿", "è¨“èª­ã¿"]
                keyword_count = sum(1 for keyword in keywords if keyword in reasoning)
                
                if keyword_count >= 3:
                    score += 0.5  # è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                elif keyword_count >= 1:
                    score += 0.2  # å°‘ãªãã¨ã‚‚1ã¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                
                # èª¬æ˜ã®é•·ã•ãŒé©åˆ‡ã‹
                reasoning_length = len(reasoning)
                if 20 < reasoning_length < 100:
                    score += 0.3
                elif 100 <= reasoning_length < 200:
                    score += 0.1
                elif reasoning_length >= 200:
                    score -= 0.2  # é•·ã™ãã‚‹èª¬æ˜ã¯ãƒšãƒŠãƒ«ãƒ†ã‚£
                
                # è‹±èªã®æ„å‘³ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
                if re.search(r'[a-zA-Z]+', reasoning):
                    score += 0.1  # è‹±èªã§ã®æ„å‘³èª¬æ˜ã¯ãƒœãƒ¼ãƒŠã‚¹
            else:
                score = -0.5  # reasoningéƒ¨åˆ†ãŒãªã„å ´åˆã®ãƒšãƒŠãƒ«ãƒ†ã‚£
            
            scores.append(score)
        
        return scores
    
    def check_word_order_quality(self, prompts=None, completions=None, completion_ids=None, answer=None, **kwargs):
        """èªé †ã‚¿ã‚¹ã‚¯ã®å“è³ªã‚’è©•ä¾¡"""
        # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¯¾å¿œ
        if prompts is not None and completions is not None:
            responses = completions
            questions = []
            for prompt in prompts:
                if isinstance(prompt, list) and len(prompt) > 0:
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‹ã‚‰æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
                    question = prompt[-1].get("content", "") if isinstance(prompt[-1], dict) else str(prompt[-1])
                else:
                    question = str(prompt)
                questions.append(question)
        else:
            # å¤ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
            responses = kwargs.get('completions', [])
            questions = [kwargs.get('question', '')]
        
        scores = []
        
        for i, response in enumerate(responses):
            # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®å ´åˆã¯æ–‡å­—åˆ—ã€å¤ã„å ´åˆã¯è¾æ›¸
            if isinstance(response, str):
                text = response
            elif isinstance(response, list) and len(response) > 0:
                text = response[0].get("content", "") if isinstance(response[0], dict) else str(response[0])
            else:
                text = ""
            
            score = 0
            
            # èªé †ã«é–¢ã™ã‚‹è©•ä¾¡
            if i < len(questions):
                question = questions[i]
                
                # reasoningéƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦èªé †ã®èª¬æ˜å“è³ªã‚’è©•ä¾¡
                reasoning_match = re.search(
                    rf"{self.reasoning_start}(.*?){self.reasoning_end}", 
                    text, re.DOTALL
                )
                
                if reasoning_match:
                    reasoning = reasoning_match.group(1)
                    
                    # èªé †ã«é–¢ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
                    order_keywords = ["èªé †", "é †ç•ª", "ä¸¦ã³æ›¿ãˆ", "åŠ©è©", "ä¸»èª", "è¿°èª", "æ–‡æ³•", "æ­£ã—ã„é †åº"]
                    keyword_count = sum(1 for keyword in order_keywords if keyword in reasoning)
                    
                    if keyword_count >= 3:
                        score += 0.5  # è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                    elif keyword_count >= 1:
                        score += 0.2  # å°‘ãªãã¨ã‚‚1ã¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                    
                    # èª¬æ˜ã®é•·ã•ãŒé©åˆ‡ã‹
                    reasoning_length = len(reasoning)
                    if 20 < reasoning_length < 150:
                        score += 0.3
                    elif 150 <= reasoning_length < 300:
                        score += 0.1
                
                # æŠ½å‡ºã•ã‚ŒãŸå›ç­”ã‚’å–å¾—
                extracted_match = self.match_format.search(text)
                if extracted_match:
                    extracted_answer = extracted_match.group(1).strip()
                    
                    # æœŸå¾…ã•ã‚Œã‚‹å›ç­”ã‚’å–å¾—
                    expected_answer = answer[i] if answer and i < len(answer) else ""
                    if isinstance(expected_answer, str) and self.solution_start in expected_answer:
                        expected_match = self.match_format.search(expected_answer)
                        if expected_match:
                            expected_answer = expected_match.group(1).strip()
                    
                    # èªé †ã®è©³ç´°è©•ä¾¡
                    if extracted_answer and expected_answer:
                        score += self._evaluate_word_order_quality(question, extracted_answer, expected_answer)
            
            scores.append(score)
        
        return scores
    
    def _evaluate_word_order_quality(self, question, extracted, expected):
        """èªé †ã®è©³ç´°è©•ä¾¡"""
        if not extracted or not expected:
            return 0
        
        bonus = 0
        
        # åŠ©è©ã®æ­£ç¢ºæ€§
        particles = ['ã¯', 'ãŒ', 'ã‚’', 'ã«', 'ã§', 'ã¨', 'ã‹ã‚‰', 'ã¾ã§', 'ã‚ˆã‚Š', 'ã‚‚', 'ã¸']
        for particle in particles:
            if particle in expected:
                expected_idx = expected.index(particle)
                if particle in extracted:
                    extracted_idx = extracted.index(particle)
                    # åŠ©è©ã®ç›¸å¯¾ä½ç½®ã®æ­£ç¢ºæ€§
                    relative_pos_expected = expected_idx / len(expected)
                    relative_pos_extracted = extracted_idx / len(extracted)
                    if abs(relative_pos_expected - relative_pos_extracted) < 0.1:
                        bonus += 0.1
        
        # ä¸»èªã®ä½ç½®ï¼ˆæ—¥æœ¬èªã§ã¯é€šå¸¸æ–‡é ­ï¼‰
        subject_markers = ['ç§ã¯', 'å½¼ã¯', 'å½¼å¥³ã¯', 'ã“ã‚Œã¯', 'ãã‚Œã¯']
        for marker in subject_markers:
            if marker in expected and marker in extracted:
                expected_pos = expected.index(marker) / len(expected)
                extracted_pos = extracted.index(marker) / len(extracted)
                if expected_pos < 0.3 and extracted_pos < 0.3:
                    bonus += 0.2
        
        # å‹•è©ã®ä½ç½®ï¼ˆæ—¥æœ¬èªã§ã¯é€šå¸¸æ–‡æœ«ï¼‰
        verb_endings = ['ã¾ã™', 'ã§ã™', 'ã§ã‚ã‚‹', 'ã ', 'ã¾ã—ãŸ', 'ã§ã—ãŸ', 'ã§ã—ã‚‡ã†']
        for ending in verb_endings:
            if expected.endswith(ending) and extracted.endswith(ending):
                bonus += 0.3
                break
        
        # èªé †ã®ä¸€èˆ¬çš„ãªæ­£ç¢ºæ€§
        expected_words = expected.split()
        extracted_words = extracted.split()
        
        if len(expected_words) == len(extracted_words):
            # ä½ç½®ãŒæ­£ã—ã„å˜èªã®å‰²åˆ
            correct_positions = sum(1 for i, (exp, ext) in enumerate(zip(expected_words, extracted_words)) if exp == ext)
            position_accuracy = correct_positions / len(expected_words)
            bonus += position_accuracy * 0.5
        
        return min(bonus, 1.0)  # æœ€å¤§1.0ã®ãƒœãƒ¼ãƒŠã‚¹
    
    def check_particle_quality(self, prompts=None, completions=None, completion_ids=None, answer=None, **kwargs):
        """åŠ©è©ç©´åŸ‹ã‚ã‚¿ã‚¹ã‚¯ã®å“è³ªã‚’è©•ä¾¡"""
        # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¯¾å¿œ
        if prompts is not None and completions is not None:
            responses = completions
            questions = []
            for prompt in prompts:
                if isinstance(prompt, list) and len(prompt) > 0:
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‹ã‚‰æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
                    question = prompt[-1].get("content", "") if isinstance(prompt[-1], dict) else str(prompt[-1])
                else:
                    question = str(prompt)
                questions.append(question)
        else:
            # å¤ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
            responses = kwargs.get('completions', [])
            questions = [kwargs.get('question', '')]
        
        scores = []
        
        # ä¸€èˆ¬çš„ãªåŠ©è©ã®ãƒªã‚¹ãƒˆ
        COMMON_PARTICLES = [
            "ãŒ", "ã‚’", "ã«", "ã§", "ã¸", "ã¨", "ã®", "ã¯", "ã‚‚", "ã‹ã‚‰", "ã¾ã§", "ã‚ˆã‚Š",
            "ã‚„", "ãªã©", "ã®ã§", "ã®ã«", "ã¦ã‚‚", "ã§ã‚‚", "ã¦ã¯", "ã«ã¯", "ã§ã¯", "ã¸ã¯"
        ]
        
        for i, response in enumerate(responses):
            # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®å ´åˆã¯æ–‡å­—åˆ—ã€å¤ã„å ´åˆã¯è¾æ›¸
            if isinstance(response, str):
                text = response
            elif isinstance(response, list) and len(response) > 0:
                text = response[0].get("content", "") if isinstance(response[0], dict) else str(response[0])
            else:
                text = ""
            
            score = 0
            
            # reasoningéƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦åŠ©è©ã®èª¬æ˜å“è³ªã‚’è©•ä¾¡
            reasoning_match = re.search(
                rf"{self.reasoning_start}(.*?){self.reasoning_end}", 
                text, re.DOTALL
            )
            
            if reasoning_match:
                reasoning = reasoning_match.group(1)
                
                # æ–‡æ³•ç”¨èªã®ä½¿ç”¨ã‚’ãƒã‚§ãƒƒã‚¯
                grammar_terms = ["ä¸»èª", "ç›®çš„èª", "å¯¾è±¡", "å ´æ‰€", "æ–¹å‘", "æ‰‹æ®µ", "ç†ç”±", "æ™‚é–“", "å‹•ä½œ", "åŠ©è©"]
                term_count = sum(1 for term in grammar_terms if term in reasoning)
                
                if term_count >= 2:
                    score += 0.5  # è¤‡æ•°ã®æ–‡æ³•ç”¨èª
                elif term_count >= 1:
                    score += 0.2  # å°‘ãªãã¨ã‚‚1ã¤ã®æ–‡æ³•ç”¨èª
                
                # èª¬æ˜ã®é•·ã•ãŒé©åˆ‡ã‹
                reasoning_length = len(reasoning)
                if 20 < reasoning_length < 150:
                    score += 0.3
                elif 150 <= reasoning_length < 250:
                    score += 0.1
            
            # æŠ½å‡ºã•ã‚ŒãŸå›ç­”ã‚’å–å¾—
            extracted_match = self.match_format.search(text)
            if extracted_match:
                extracted_answer = extracted_match.group(1).strip()
                
                # åŠ©è©ã¨ã—ã¦å¦¥å½“ã‹ãƒã‚§ãƒƒã‚¯
                if extracted_answer in COMMON_PARTICLES:
                    score += 0.5  # ä¸€èˆ¬çš„ãªåŠ©è©ãªã‚‰åŠ ç‚¹
                elif len(extracted_answer) <= 3:  # çŸ­ã„æ–‡å­—åˆ—ãªã‚‰åŠ©è©ã®å¯èƒ½æ€§
                    score += 0.2
            
            scores.append(score)
        
        return scores
    
    def check_counter_quality(self, prompts=None, completions=None, completion_ids=None, answer=None, **kwargs):
        """åŠ©æ•°è©ã‚¿ã‚¹ã‚¯ã®å“è³ªã‚’è©•ä¾¡"""
        # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¯¾å¿œ
        if prompts is not None and completions is not None:
            responses = completions
            questions = []
            for prompt in prompts:
                if isinstance(prompt, list) and len(prompt) > 0:
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‹ã‚‰æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
                    question = prompt[-1].get("content", "") if isinstance(prompt[-1], dict) else str(prompt[-1])
                else:
                    question = str(prompt)
                questions.append(question)
        else:
            # å¤ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
            responses = kwargs.get('completions', [])
            questions = [kwargs.get('question', '')]
        
        scores = []
        
        # ä¸€èˆ¬çš„ãªåŠ©æ•°è©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        COMMON_COUNTERS = [
            "ã¤", "å€‹", "æœ¬", "æš", "å°", "äºº", "åŒ¹", "é ­", "ç¾½", "å†Š", "å›", 
            "åº¦", "ç•ª", "è¶³", "ç€", "æ¯", "å††", "æ­³", "æ™‚", "åˆ†", "ç§’", "æ—¥",
            "æœˆ", "å¹´", "é€±é–“", "ãƒ¶æœˆ", "éš", "è»’", "é€š", "ä»¶", "å", "æ©Ÿ"
        ]
        
        for i, response in enumerate(responses):
            # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®å ´åˆã¯æ–‡å­—åˆ—ã€å¤ã„å ´åˆã¯è¾æ›¸
            if isinstance(response, str):
                text = response
            elif isinstance(response, list) and len(response) > 0:
                text = response[0].get("content", "") if isinstance(response[0], dict) else str(response[0])
            else:
                text = ""
            
            score = 0
            
            # reasoningéƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦åŠ©æ•°è©ã®èª¬æ˜å“è³ªã‚’è©•ä¾¡
            reasoning_match = re.search(
                rf"{self.reasoning_start}(.*?){self.reasoning_end}", 
                text, re.DOTALL
            )
            
            if reasoning_match:
                reasoning = reasoning_match.group(1)
                
                # åŠ©æ•°è©ã«é–¢ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
                counter_keywords = ["åŠ©æ•°è©", "æ•°ãˆã‚‹", "ã‚«ã‚¦ãƒ³ãƒˆ", "å˜ä½", "æ•°å­—", "æ•°é‡", "å€‹æ•°", "ç‰©ã®å½¢", "åˆ†é¡"]
                keyword_count = sum(1 for keyword in counter_keywords if keyword in reasoning)
                
                if keyword_count >= 2:
                    score += 0.5  # è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                elif keyword_count >= 1:
                    score += 0.2  # å°‘ãªãã¨ã‚‚1ã¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                
                # éŸ³å¤‰åŒ–ã®èª¬æ˜ãŒã‚ã‚‹ã‹
                sound_change_keywords = ["éŸ³å¤‰åŒ–", "èª­ã¿æ–¹", "ç™ºéŸ³", "ã„ã¡", "ã«", "ã•ã‚“", "ã‚ˆã‚“", "ã”", "ã‚ã", "ãªãª", "ã¯ã¡", "ãã‚…ã†", "ã˜ã‚…ã†"]
                if any(keyword in reasoning for keyword in sound_change_keywords):
                    score += 0.3
                
                # èª¬æ˜ã®é•·ã•ãŒé©åˆ‡ã‹
                reasoning_length = len(reasoning)
                if 30 < reasoning_length < 200:
                    score += 0.3
                elif 200 <= reasoning_length < 300:
                    score += 0.1
            
            # æŠ½å‡ºã•ã‚ŒãŸå›ç­”ã‚’å–å¾—
            extracted_match = self.match_format.search(text)
            if extracted_match:
                extracted_answer = extracted_match.group(1).strip()
                
                # åŠ©æ•°è©ã¨ã—ã¦å¦¥å½“ã‹ãƒã‚§ãƒƒã‚¯
                if any(counter in extracted_answer for counter in COMMON_COUNTERS):
                    score += 0.5  # ä¸€èˆ¬çš„ãªåŠ©æ•°è©ã‚’å«ã‚€
                # æ•°å­—ï¼‹åŠ©æ•°è©ã®å½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
                elif re.match(r'^[0-9ï¼-ï¼™ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡å„„]+[ã-ã‚“ã‚¡-ãƒ³ã€…]+$', extracted_answer):
                    score += 0.4
                elif len(extracted_answer) <= 10:  # çŸ­ã„æ–‡å­—åˆ—ãªã‚‰åŠ©æ•°è©ã®å¯èƒ½æ€§
                    score += 0.2
            
            scores.append(score)
        
        return scores
    
    def check_keigo_quality(self, prompts=None, completions=None, completion_ids=None, answer=None, **kwargs):
        """æ•¬èªå¤‰æ›ã‚¿ã‚¹ã‚¯ã®å“è³ªã‚’è©•ä¾¡"""
        # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¯¾å¿œ
        if prompts is not None and completions is not None:
            responses = completions
            questions = []
            for prompt in prompts:
                if isinstance(prompt, list) and len(prompt) > 0:
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‹ã‚‰æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
                    question = prompt[-1].get("content", "") if isinstance(prompt[-1], dict) else str(prompt[-1])
                else:
                    question = str(prompt)
                questions.append(question)
        else:
            # å¤ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
            responses = kwargs.get('completions', [])
            questions = [kwargs.get('question', '')]
        
        scores = []
        
        # æ•¬èªã®ãƒãƒ¼ã‚«ãƒ¼
        KEIGO_MARKERS = {
            "å°Šæ•¬èª": ["ã‚Œã‚‹", "ã‚‰ã‚Œã‚‹", "ã„ã‚‰ã£ã—ã‚ƒã‚‹", "ãŠã£ã—ã‚ƒã‚‹", "å¬ã—ä¸ŠãŒã‚‹", "ãŠ/ã”ï½ã«ãªã‚‹", "ï½ã‚Œã¾ã™", "ï½ã‚‰ã‚Œã¾ã™"],
            "è¬™è­²èª": ["ã„ãŸã™", "ç”³ã™", "ä¼ºã†", "æ‹è¦‹", "ãŠ/ã”ï½ã™ã‚‹", "ã•ã›ã¦ã„ãŸã ã", "ã„ãŸã—ã¾ã™", "ç”³ã—ä¸Šã’ã‚‹"],
            "ä¸å¯§èª": ["ã§ã™", "ã¾ã™", "ã”ã–ã„ã¾ã™", "ã§ã”ã–ã„ã¾ã™"]
        }
        
        for i, response in enumerate(responses):
            # æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®å ´åˆã¯æ–‡å­—åˆ—ã€å¤ã„å ´åˆã¯è¾æ›¸
            if isinstance(response, str):
                text = response
            elif isinstance(response, list) and len(response) > 0:
                text = response[0].get("content", "") if isinstance(response[0], dict) else str(response[0])
            else:
                text = ""
            
            score = 0
            
            # reasoningéƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦æ•¬èªã®èª¬æ˜å“è³ªã‚’è©•ä¾¡
            reasoning_match = re.search(
                rf"{self.reasoning_start}(.*?){self.reasoning_end}", 
                text, re.DOTALL
            )
            
            if reasoning_match:
                reasoning = reasoning_match.group(1)
                
                # æ•¬èªã®ç¨®é¡ã«é–¢ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
                keigo_keywords = ["æ•¬èª", "å°Šæ•¬èª", "è¬™è­²èª", "ä¸å¯§èª", "ç¾åŒ–èª", "æ•¬æ„", "ç›¸æ‰‹", "ç«‹å ´", "ä¸Šä¸‹é–¢ä¿‚"]
                keyword_count = sum(1 for keyword in keigo_keywords if keyword in reasoning)
                
                if keyword_count >= 3:
                    score += 0.5  # è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                elif keyword_count >= 1:
                    score += 0.2  # å°‘ãªãã¨ã‚‚1ã¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                
                # å…·ä½“çš„ãªæ•¬èªå½¢å¼ã®èª¬æ˜ãŒã‚ã‚‹ã‹
                if any(marker in reasoning for markers in KEIGO_MARKERS.values() for marker in markers):
                    score += 0.3
                
                # èª¬æ˜ã®é•·ã•ãŒé©åˆ‡ã‹
                reasoning_length = len(reasoning)
                if 30 < reasoning_length < 200:
                    score += 0.3
                elif 200 <= reasoning_length < 300:
                    score += 0.1
            
            # æŠ½å‡ºã•ã‚ŒãŸå›ç­”ã‚’å–å¾—
            extracted_match = self.match_format.search(text)
            if extracted_match:
                extracted_answer = extracted_match.group(1).strip()
                
                # æ•¬èªãƒãƒ¼ã‚«ãƒ¼ã‚’å«ã‚€ã‹ãƒã‚§ãƒƒã‚¯
                keigo_score = 0
                for keigo_type, markers in KEIGO_MARKERS.items():
                    if any(marker in extracted_answer for marker in markers):
                        keigo_score += 0.3
                        break
                
                # æ–‡æœ«ãŒæ•¬èªã‚‰ã—ã„ã‹ãƒã‚§ãƒƒã‚¯
                if extracted_answer.endswith(("ã¾ã™", "ã§ã™", "ã¾ã—ãŸ", "ã§ã—ãŸ", "ã”ã–ã„ã¾ã™", "ã„ãŸã—ã¾ã™")):
                    keigo_score += 0.2
                
                score += min(keigo_score, 0.5)  # æœ€å¤§0.5ç‚¹
            
            scores.append(score)
        
        return scores
    
    def get_all_reward_functions(self):
        """ã™ã¹ã¦ã®å ±é…¬é–¢æ•°ã‚’ãƒªã‚¹ãƒˆã§è¿”ã™"""
        return [
            self.match_format_exactly,
            self.match_format_approximately,
            self.check_answer,
            self.check_reasoning_quality,
            self.check_word_order_quality,
            self.check_particle_quality,
            self.check_counter_quality,
            self.check_keigo_quality
        ]
    
    def get_accuracy_summary(self):
        """ç²¾åº¦çµ±è¨ˆã®ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        if not self.accuracy_stats['correct_answer']:
            return None
        
        total_attempts = len(self.accuracy_stats['correct_answer'])
        correct_rate = sum(self.accuracy_stats['correct_answer']) / total_attempts * 100
        format_rate = sum(self.accuracy_stats['correct_format']) / len(self.accuracy_stats['correct_format']) * 100
        
        return {
            'total_attempts': total_attempts,
            'correct_rate': correct_rate,
            'format_rate': format_rate,
            'partial_rate': sum(self.accuracy_stats.get('partial_answer', [])) / total_attempts * 100,
            'no_answer_rate': sum(self.accuracy_stats.get('no_answer', [])) / total_attempts * 100
        }